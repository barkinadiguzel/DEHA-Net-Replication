# ğŸœ‚ DEHA-Net-Replication â€” Dual-Encoder Hard Attention Segmentation Framework

This repository provides a **PyTorch-based research replication** of  
**DEHA-Net: A Dual-Encoder-Based Hard Attention Network with an Adaptive ROI Mechanism for Lung Nodule Segmentation**,  
implemented as a **theory-faithful medical segmentation framework**.

The project translates the paperâ€™s **dual-encoder topology, hard attention gates, adaptive ROI mechanism, and tri-planar consensus inference**
into a clean, modular, and extensible research codebase.

- Enables **high-precision lung nodule segmentation from CT slices** ğŸ«  
- Implements **globalâ€“local dual-encoder representation learning** ğŸ§   
- Integrates **hard attention gating for region-focused feature fusion** ğŸœ„  
- Employs **adaptive ROI refinement for coarse-to-fine segmentation** ğŸœ  
- Supports **tri-planar consensus inference (axial, coronal, sagittal)** ğŸœƒ  

**Paper reference:**  [DEHA-Net: Dual-Encoder Hard Attention Network with Adaptive ROI for Lung Nodule Segmentation (2023)](https://www.mdpi.com/1424-8220/23/4/1989) ğŸ“„


---

## ğŸ† Overview â€” Dual-Encoder Hard Attention Segmentation Pipeline

ğŸœ‚ Global Encoder â†’ ğŸœ„ Local Encoder â†’ ğŸœ Hard Attention â†’ ğŸœƒ Adaptive ROI â†’ ğŸœ€ Decoder â†’ ğŸ« Segmentation Mask

The core idea:

> Lung nodules are small, heterogeneous, and easily confused with vessels and bronchi.  
> Accurate segmentation requires both global anatomical context and local fine-grained focus.

Instead of relying on a single encoder, DEHA-Net performs **dual-stream feature extraction**:

$$
I \longrightarrow \hat{Y}
$$

where the model learns a slice-wise mapping

$$
f_\theta : \mathbb{R}^{H \times W} \rightarrow \mathbb{R}^{H \times W}
$$

and produces a dense segmentation mask $\hat{Y}$ from a CT slice $I$.

The architecture follows a **dual-encoder + attention-gated decoder design** enriched with an  
**Adaptive Region of Interest (A-ROI) refinement mechanism**.

---

## ğŸ§  Architectural Principle â€” DEHA-Net

The network consists of two parallel encoders:

- **Global Encoder** ğŸœ‚ â€” learns anatomical context and coarse localization  
- **Local Encoder** ğŸœ„ â€” learns fine-grained nodule appearance from ROI patches  

At each decoding stage, features are fused using **Hard Attention Gates**:

$$
\alpha = \sigma(\psi(\text{ReLU}(W_g g + W_l l)))
$$

$$
\hat{l} = \alpha \odot l
$$

where  
$g$ is the global feature,  
$l$ is the local feature,  
and $\alpha$ is the spatial attention mask.

This forces the decoder to focus only on **nodule-relevant regions**.

---

## ğŸœ Adaptive ROI Mechanism (A-ROI)

The Adaptive ROI module refines segmentation via a coarse-to-fine strategy.

Given an initial probability map $P$:

$$
ROI = \{ p \mid P(p) > R_T \}
$$

A bounding box is extracted around high-confidence pixels and expanded with a margin.

This ROI is then cropped and re-fed into the local encoder for refined prediction.

This mimics a **radiologist zooming into a suspicious region**.

---

## ğŸœƒ Tri-Planar Consensus Inference

CT volumes are interpreted along three anatomical planes:

- Axial  
- Coronal  
- Sagittal  

Each view is segmented independently and fused via consensus:

$$
\hat{Y} = \frac{Y_{axial} + Y_{coronal} + Y_{sagittal}}{3}
$$

This provides **3D spatial consistency** from a 2D network.

---

## ğŸ”¬ Mathematical Formulation

Let the input CT slice be

$$
I \in \mathbb{R}^{H \times W}
$$

The network learns a pixel-wise classifier:

$$
p(y_{ij} \mid I) = \sigma(f_\theta(I)_{ij})
$$

Training is performed using Dice loss:

$$
\text{Dice} = \frac{2|P \cap G|}{|P| + |G|}
$$

$$
\mathcal{L}_{dice} = 1 - \text{Dice}
$$

where  
$P$ is the predicted mask and  
$G$ is the ground-truth mask.

This directly optimizes spatial overlap â€” critical for medical segmentation.

---

## ğŸ§ª What the Model Learns

- To distinguish nodules from vessels and bronchi ğŸœ‡  
- To focus attention only on suspicious regions ğŸœ„  
- To refine segmentation via adaptive zooming ğŸœ  
- To preserve fine boundary geometry ğŸ€  
- To reason across 3D anatomy using multi-view consensus ğŸœƒ  

Segmentation becomes a **context-aware, attention-guided reasoning task**.

---

## ğŸ“¦ Repository Structure

```bash
DEHA-Net-Replication/
â”œâ”€â”€ src/
â”‚
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ encoders.py           # Global + Local encoder
â”‚   â”‚   â”œâ”€â”€ attention.py          # Hard Attention Gate (paper equation)
â”‚   â”‚   â”œâ”€â”€ decoder.py            # Decoder blocks
â”‚   â”‚   â””â”€â”€ deha_net.py           # Full DEHA-Net assembly
â”‚   â”‚
â”‚   â”œâ”€â”€ roi/
â”‚   â”‚   â”œâ”€â”€ adaptive_roi.py       # A-ROI algorithm (paper Section 3.3)
â”‚   â”‚   â””â”€â”€ roi_utils.py          # Bounding box, margin, propagation
â”‚   â”‚
â”‚   â”œâ”€â”€ consensus/
â”‚   â”‚   â””â”€â”€ consensus_module.py   # Axial + Sagittal + Coronal fusion
â”‚   â”‚
â”‚   â”œâ”€â”€ dataset/
â”‚   â”‚   â””â”€â”€ lidc_loader.py
â”‚   â”‚
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â””â”€â”€ inference_pipeline.py # Paper inference flow
â”‚   â”‚
â”‚   â”œâ”€â”€ visualization/
â”‚   â”‚   â””â”€â”€ overlay.py            # CT + ROI + Mask overlay
â”‚   â”‚
â”‚   â””â”€â”€ config.py
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
---


## ğŸ”— Feedback

For questions or feedback, contact: [barkin.adiguzel@gmail.com](mailto:barkin.adiguzel@gmail.com)
